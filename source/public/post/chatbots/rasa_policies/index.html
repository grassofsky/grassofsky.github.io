<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>对话系统rasa - Policies （翻译） - grassofsky notebook</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="grassofsky" /><meta name="description" content="对话系统rasa - Policies （翻译） Configuring Policies rasa.core.policies.Policy用来确定对话过程中每个步骤将要采取什么Action。 这里有" /><meta name="keywords" content="grassofsky, notebook" />






<meta name="generator" content="Hugo 0.62.0 with theme even" />


<link rel="canonical" href="http://localhost:1313/post/chatbots/rasa_policies/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">


<link href="/dist/even.c2a46f00.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="对话系统rasa - Policies （翻译）" />
<meta property="og:description" content="对话系统rasa - Policies （翻译） Configuring Policies rasa.core.policies.Policy用来确定对话过程中每个步骤将要采取什么Action。 这里有" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/post/chatbots/rasa_policies/" />
<meta property="article:published_time" content="2019-12-21T00:00:00+00:00" />
<meta property="article:modified_time" content="2019-12-21T00:00:00+00:00" />
<meta itemprop="name" content="对话系统rasa - Policies （翻译）">
<meta itemprop="description" content="对话系统rasa - Policies （翻译） Configuring Policies rasa.core.policies.Policy用来确定对话过程中每个步骤将要采取什么Action。 这里有">
<meta itemprop="datePublished" content="2019-12-21T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2019-12-21T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="6738">



<meta itemprop="keywords" content="rasa-doc," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="对话系统rasa - Policies （翻译）"/>
<meta name="twitter:description" content="对话系统rasa - Policies （翻译） Configuring Policies rasa.core.policies.Policy用来确定对话过程中每个步骤将要采取什么Action。 这里有"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Even</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Even</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">对话系统rasa - Policies （翻译）</h1>

      <div class="post-meta">
        <span class="post-time"> 2019-12-21 </span>
        <div class="post-category">
            <a href="/categories/chatbot/"> chatbot </a>
            <a href="/categories/rasa/"> rasa </a>
            <a href="/categories/%E7%BF%BB%E8%AF%91/"> 翻译 </a>
            </div>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#configuring-policies">Configuring Policies</a>
      <ul>
        <li><a href="#max-history">Max History</a></li>
        <li><a href="#data-augmentation">Data Augmentation</a></li>
      </ul>
    </li>
    <li><a href="#action-selection">Action Selection</a></li>
    <li><a href="#keras-policy">Keras Policy</a></li>
    <li><a href="#embedding-policy">Embedding Policy</a></li>
    <li><a href="#mapping-policy">Mapping Policy</a></li>
    <li><a href="#memoization-policy">Memoization Policy</a></li>
    <li><a href="#fallback-policy">Fallback Policy</a></li>
    <li><a href="#two-stage-fallback-policy">Two-Stage Fallback Policy</a></li>
    <li><a href="#form-policy">Form Policy</a></li>
    <li><a href="#heading">原文链接</a></li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <h1 id="rasa---policies-">对话系统rasa - Policies （翻译）</h1>
<h2 id="configuring-policies">Configuring Policies</h2>
<p><code>rasa.core.policies.Policy</code>用来确定对话过程中每个步骤将要采取什么Action。</p>
<p>这里有不同的policies用来选择，并且你可以将多个policies包含在一个<code>rasa.core.agent.Agent</code>中。</p>
<p><strong>注意</strong>：针对每个用户消息，默认可预测的最大action数量为10。你可以通过设置环境变量<code>MAX_NUMBER_OF_PREDICTIONS</code>来改变这个值。</p>
<p>你的项目中的config.yml配置文件有一个policies关键字用来设定你的助手将会使用哪些policies。下面的例子中，最后两行是针对你的自定义的policy类以及需要的参数。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">policies:
  - name: &#34;KerasPolicy&#34;
    featurizer:
    - name: MaxHistoryTrackerFeaturizer
      max_history: 5
      state_featurizer:
        - name: BinarySingleStateFeaturizer
  - name: &#34;MemoizationPolicy&#34;
    max_history: 5
  - name: &#34;FallbackPolicy&#34;
    nlu_threshold: 0.4
    core_threshold: 0.3
    fallback_action_name: &#34;my_fallback_action&#34;
  - name: &#34;path.to.your.policy.class&#34;
    arg1: &#34;...&#34;
</code></pre></td></tr></table>
</div>
</div><h3 id="max-history">Max History</h3>
<p>针对rasa core policies的一个重要的超参数是<code>max_history</code>。这个控制了当确定要采用哪个action的时候，需要考虑的对话历史的数量。</p>
<p>你可以在配置文件中针对Featurizer policy传入max_history参数。</p>
<p><strong>注意</strong>：只有MaxHistoryTrackerFeaturizer使用了最大历史，而FullDialogueTrackerFeaturizer总是查看整个对话历史。具体参见：<a href="https://zhuanlan.zhihu.com/p/88111971">Featurization</a>。</p>
<p>作为示例，假设有一个<code>out_of_scope</code>的意图用来表示用户消息脱离主题了。如果你的助手多次看到了这个意图，也许你想要告诉用户你有什么可以帮助他们。因此你的故事看上去是这样的：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">* out_of_scope
   - utter_default
* out_of_scope
   - utter_default
* out_of_scope
   - utter_help_message
</code></pre></td></tr></table>
</div>
</div><p>为了让rasa core学会这个模式，<code>max_history</code>需要至少被设置成3。</p>
<p>如果你增加<code>max_history</code>，你的模型将会变得更大，训练时间也会变得更常。如果你的一些消息会在未来的某个地方影响到对话，你应该将它存储成slot。slot针对每个featurizer都是可用的。</p>
<h3 id="data-augmentation">Data Augmentation</h3>
<p>在训练模型时，默认情况下，Rasa Core将随机地将故事文件中的故事粘在一起，从而创建更长的故事。这是因为如果你有这样的故事：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback"># thanks
* thankyou
   - utter_youarewelcome

# bye
* goodbye
   - utter_goodbye
</code></pre></td></tr></table>
</div>
</div><p>实际上，你想要这样训练你的策略，在对话历史不相关的情况下忽略对话历史，不管之前发生了什么，只要用同样的行动来回应。</p>
<p>你可以通过使用<code>--augmentation</code>来改变这种行为。这个参数允许你设置<code>augmentation_factor</code>。<code>augmentation_factor</code>参数决定在训练的时候有多少augmented故事是子采样的。扩增的故事是在训练之前进行采样的，由于他们的数量增加的很快，因此我们需要限制它。采样的故事的数量是<code>augmentation_factor</code>的10倍。默认情况下<code>augmentation</code>是20，因此最大是200个augmentated故事。</p>
<p><code>--augmentation 0</code>将禁止所有的augmentation行为。基于记忆的policies不会受这个参数的影响，会自动忽略所有扩增的故事。</p>
<h2 id="action-selection">Action Selection</h2>
<p>每一轮对话中，定义在配置文件中的每个policy在预测下一个action的时候都会有对应的置信度。想要了解关于每个policy如何做出预测的，可以阅读下面更加详细的介绍。助手会从这些预测中选择出置信度最高的结果。</p>
<p>如果两个策略得到相同的置信度（比如，memorization和mapping policy的置信度总是1或0），将会考虑到policies的优先级。rasa policies为各个policy设定了默认优先级。他们看上去是这样的，更大的数值意味着更高的优先级：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">5. FormPolicy
4. FallbackPolicy and TwoStageFallbackPolicy
3. MemoizationPolicy and AugmentedMemoizationPolicy
2. MappingPolicy
1. EmbeddingPolicy, KerasPolicy, and SklearnPolicy
</code></pre></td></tr></table>
</div>
</div><p>优先级设置的情况下，确保了如下行为，如果有个意图预测为mapped action，但是NLU值不高于<code>nlu_threshold</code>，bot仍然会fall back。通常情况下，不建议使用相同优先级的多个策略。</p>
<p>如果你创建自己的policy，使用上面的优先级顺序来指导设定你的优先级。比如，你创建了基于深度学习的策略，你的优先级应该是1，和rasa的深度学习策略的优先级保持一致。</p>
<p><strong>警告</strong>：所有的policy的优先级都可以通过<code>priority:</code>参数进行设定，但是我们不建议除了自定义policy以外的策略上进行使用。否则可能会有意料之外的结果。</p>
<h2 id="keras-policy">Keras Policy</h2>
<p><code>KerasPolicy</code>使用了基于Keras实现的神经网络选择下一个action。默认的结构是基于LSTM试下你的，但是你可以重写KerasPolicy.model_architecture方法，来实现你自己的网络结构。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">model_architecture</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-</span><span class="o">&gt;</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
    <span class="sa"></span><span class="s2">&#34;&#34;&#34;</span><span class="s2">Build a keras model and return a compiled model.</span><span class="s2">&#34;&#34;&#34;</span>

    <span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
    <span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="p">(</span>
        <span class="n">Masking</span><span class="p">,</span>
        <span class="n">LSTM</span><span class="p">,</span>
        <span class="n">Dense</span><span class="p">,</span>
        <span class="n">TimeDistributed</span><span class="p">,</span>
        <span class="n">Activation</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Build Model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="p">)</span>

    <span class="c1"># the shape of the y vector of the labels,</span>
    <span class="c1"># determines which output from rnn will be used</span>
    <span class="c1"># to calculate the loss</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># y is (num examples, num features) so</span>
        <span class="c1"># only the last output from the rnn is used to</span>
        <span class="c1"># calculate the loss</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Masking</span><span class="p">(</span><span class="n">mask_value</span><span class="o">=</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">)</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">input_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="n">output_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="p">)</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="c1"># y is (num examples, max_dialogue_len, num features) so</span>
        <span class="c1"># all the outputs from the rnn are used to</span>
        <span class="c1"># calculate the loss, therefore a sequence is returned and</span>
        <span class="c1"># time distributed layer is used</span>

        <span class="c1"># the first value in input_shape is max dialogue_len,</span>
        <span class="c1"># it is set to None, to allow dynamic_rnn creation</span>
        <span class="c1"># during prediction</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Masking</span><span class="p">(</span><span class="n">mask_value</span><span class="o">=</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="p">)</span><span class="p">)</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">output_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="p">)</span><span class="p">)</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa"></span><span class="s2">&#34;</span><span class="s2">Cannot construct the model because</span><span class="s2">&#34;</span>
            <span class="sa"></span><span class="s2">&#34;</span><span class="s2">length of output_shape = {} </span><span class="s2">&#34;</span>
            <span class="sa"></span><span class="s2">&#34;</span><span class="s2">should be 1 or 2.</span><span class="s2">&#34;</span>
            <span class="sa"></span><span class="s2">&#34;</span><span class="s2">&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">softmax</span><span class="s2">&#34;</span><span class="p">)</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">loss</span><span class="o">=</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">categorical_crossentropy</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">rmsprop</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">accuracy</span><span class="s2">&#34;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">obtain_verbosity</span><span class="p">(</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span>
</code></pre></td></tr></table>
</div>
</div><p>训练的代码是这样的：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">train</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">training_trackers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">DialogueStateTracker</span><span class="p">]</span><span class="p">,</span>
    <span class="n">domain</span><span class="p">:</span> <span class="n">Domain</span><span class="p">,</span>
    <span class="o">*</span><span class="o">*</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-</span><span class="o">&gt;</span> <span class="bp">None</span><span class="p">:</span>

    <span class="c1"># set numpy random seed</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>

    <span class="n">training_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">featurize_for_training</span><span class="p">(</span><span class="n">training_trackers</span><span class="p">,</span> <span class="n">domain</span><span class="p">,</span> <span class="o">*</span><span class="o">*</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="c1"># noinspection PyPep8Naming</span>
    <span class="n">shuffled_X</span><span class="p">,</span> <span class="n">shuffled_y</span> <span class="o">=</span> <span class="n">training_data</span><span class="o">.</span><span class="n">shuffled_X_y</span><span class="p">(</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">(</span><span class="p">)</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">(</span><span class="p">)</span><span class="p">:</span>
        <span class="c1"># set random seed in tf</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">session</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tf_config</span><span class="p">)</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">as_default</span><span class="p">(</span><span class="p">)</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_architecture</span><span class="p">(</span>
                    <span class="n">shuffled_X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="p">]</span><span class="p">,</span> <span class="n">shuffled_y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="p">]</span>
                <span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa"></span><span class="s2">&#34;</span><span class="s2">Fitting model with {} total samples and a </span><span class="s2">&#34;</span>
                <span class="sa"></span><span class="s2">&#34;</span><span class="s2">validation split of {}</span><span class="s2">&#34;</span>
                <span class="sa"></span><span class="s2">&#34;</span><span class="s2">&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">training_data</span><span class="o">.</span><span class="n">num_examples</span><span class="p">(</span><span class="p">)</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation_split</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="c1"># filter out kwargs that cannot be passed to fit</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_train_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_valid_params</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">,</span> <span class="o">*</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_params</span>
            <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                <span class="n">shuffled_X</span><span class="p">,</span>
                <span class="n">shuffled_y</span><span class="p">,</span>
                <span class="n">epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="n">obtain_verbosity</span><span class="p">(</span><span class="p">)</span><span class="p">,</span>
                <span class="o">*</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_params</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># the default parameter for epochs in keras fit is 1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">defaults</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">epochs</span><span class="s2">&#34;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">Done fitting keras policy model</span><span class="s2">&#34;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>你可以通过重写这些方法，实现自己的模型，或者使用预定义的<code>keras model</code>初始化keraspolicy。</p>
<p>为了针对相同的输入得到重用的训练结果，你可以将KerasPolicy的random_seed设置成任何整数。</p>
<h2 id="embedding-policy">Embedding Policy</h2>
<p>Transformer Embedding Dialogue Policy。</p>
<p>Transformer version of the Recurrent Embedding Dialogue Policy 在我们的文章中被使用，如下：https://arxiv.org/abs/1811.11707</p>
<p>这个policy有预定义的架构，由以下步骤组成：</p>
<ul>
<li>将用户输入（用户意图和实体），之前的系统响应，slots，针对每个时间步的active form，组成一个输入向量用于pre-transformer embedding layer</li>
<li>把它传递给transformer</li>
<li>在transformer的输出后面连接一个密集层，用来获取每个时间步的对话嵌入</li>
<li>添加一个密集来创建用于每个时间步系统响应的嵌入</li>
<li>计算对话嵌入和嵌入的系统响应之间的相似度。这个过程是基于<a href="https://arxiv.org/abs/1709.03856">StarSpace</a> 的思想。</li>
</ul>
<p>建议使用<code>state_featurizer=LabelTokenizerSingleStateFeaturizer(...)</code>（详细见：<a href="https://zhuanlan.zhihu.com/p/88111971">Featurization</a>）。</p>
<p><strong>配置</strong>：</p>
<p>配置文件中的配置参数可以传递给<code>EmbeddingPolicy</code>。</p>
<p><strong>警告</strong>：传递合适的<code>epochs</code>给<code>EmbeddingPolicy</code>，否则policy将会被训练为1 epoch。</p>
<p>该算法包括如下超参数：</p>
<ul>
<li>神经网络结构相关：
<ul>
<li><code>hidden_layers_sizes_b</code>：设定system actions嵌入层之前的隐藏层大小（list），隐藏层的数量等于列表长度；</li>
<li><code>transformer_size</code>：设定transformer中单元的数量；</li>
<li><code>num_transformer_layers</code>：设定transformer层数；</li>
<li><code>pos_encoding</code>：设定transformer位置编码的类型，可以是<code>timing</code>或<code>emb</code>；</li>
<li><code>max_seq_length</code>：如果使用位置编码，则设置最大序列长度；</li>
<li><code>num_heads</code>：设置multihead attention中heads的数量；</li>
</ul>
</li>
<li>training：
<ul>
<li><code>batch_size</code>：设置一次前向反向计算的训练数据的数量，batch size的值越大，需要的内存空间就越大；</li>
<li><code>batch_strategy</code>：设置batching的策略，<code>sequence</code>或<code>balanced</code>；</li>
<li><code>epochs</code>：设置算法遇到所有训练数据的次数，一个epoch表示所有训练的数据的一次前向和后向计算；</li>
<li><code>random_seed</code>：如果设置为任何int，将获得相同输入的可重复训练结果；</li>
</ul>
</li>
<li>embedding：
<ul>
<li><code>embed_dim</code>：设置嵌入空间的维度；</li>
<li><code>num_neg</code>：设置不正确的意图标签的数量，算法在训练过程中将其与用户输入的相似度最小化；</li>
<li><code>similarity_type</code>：设置相似度计算的类型，它可以使<code>auto</code>，<code>cosine</code>或者<code>inner</code>，如果是<code>auto</code>，这个类型的设置将依赖于<code>loss_type</code>，对于<code>softmax</code>采用<code>inner</code>，针对<code>margin</code>使用<code>cosine</code>；</li>
<li><code>loss_type</code>：设置损失函数的类型，<code>softmax</code>或<code>margin</code>；</li>
<li><code>mu_pos</code>：控制算法应尝试为正确的意图标签生成嵌入向量的相似程度，只有到<code>loss_type</code>设置为<code>margin</code>的时候才使用；</li>
<li><code>mu_neg</code>：控制不正确意图的最大负相似度，只有到<code>loss_type</code>设置为<code>margin</code>的时候才使用；</li>
<li><code>use_max_sim_neg</code>：如果是真的，算法只在不正确的意图标签上最小化最大相似度，只有到<code>loss_type</code>设置为<code>margin</code>的时候才使用；</li>
<li><code>scale_loss</code>：如果是真的，算法将缩小损失，例如以高置信度预测的正确的标签，只有到<code>loss_type</code>设置为<code>softmax</code>的时候才使用；</li>
</ul>
</li>
<li>regularization：
<ul>
<li><code>C2</code>：L2正则化的比例</li>
<li><code>C_emb</code>：设置最小化不同意图标签embeddings之间最大相似度的比例，只有到<code>loss_type</code>设置为<code>margin</code>的时候才使用；</li>
<li><code>droprate_a</code>：为用户输入设置嵌入层之前层之间的dropout；</li>
<li><code>droprate_b</code>：设置系统动作嵌入层前各层之间的dropout；</li>
</ul>
</li>
<li>训练准确度计算：
<ul>
<li><code>evaluate_every_num</code>：设置计算训练精度的频率，小值可能会影响性能；</li>
<li><code>evaluate_on_num_examples</code>：从验证集中挑选出多少示例来计算验证的准确度，较大值可能会影响性能。</li>
</ul>
</li>
</ul>
<p><strong>警告</strong>：这个policy默认的<code>max_history</code>值为None，意味着使用<code>FullDialogueTrackerFeaturizer</code>。我们建议设置这个值，进而使用<code>MaxHistoryTrackerFeaturizer</code>用于快速训练。我们建议增加<code>MaxHistoryTrackerFeaturizer</code> 的<code>batch_size</code>（如，<code>&quot;batch_size&quot;:[32, 64]</code>）</p>
<p><strong>警告</strong>：如果evaluate_on_num_examples为非零，则通过分层分割选取随机样本作为验证集，并将其排除在训练数据之外。如果数据集包含许多独特的对话转换示例，我们建议将其设置为零。</p>
<p><strong>注意</strong>：droprate应该是0到1之间的值，例如，<code>droprate=0.1</code>，将drop out 10%的输入单元。</p>
<p><strong>注意</strong>：针对cosine相似度，<code>mu_pos</code>和<code>mu_neg</code>的值应该在-1到1之间。</p>
<p><strong>注意</strong>：有一个选项可以使用线性增加的批处理大小。这个想法来自于<a href="https://arxiv.org/abs/1711.00489">https://arxiv.org/abs/1711.00489</a>. 为了使用这个功能，将<code>batch_size</code>设置成列表值，如，<code>&quot;batch_size&quot;: [8, 32]</code>。如果<code>batch_size</code>是常量，传入int，如，<code>&quot;batch_size&quot;: 8</code>。</p>
<p>这个参数可以在配置文件中设置，默认值定义在<code>EmbeddingPolicy.defaults</code>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="n">defaults</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># nn architecture</span>
    <span class="c1"># a list of hidden layers sizes before user embed layer</span>
    <span class="c1"># number of hidden layers is equal to the length of this list</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">hidden_layers_sizes_pre_dial</span><span class="s2">&#34;</span><span class="p">:</span> <span class="p">[</span><span class="p">]</span><span class="p">,</span>
    <span class="c1"># a list of hidden layers sizes before bot embed layer</span>
    <span class="c1"># number of hidden layers is equal to the length of this list</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">hidden_layers_sizes_bot</span><span class="s2">&#34;</span><span class="p">:</span> <span class="p">[</span><span class="p">]</span><span class="p">,</span>
    <span class="c1"># number of units in transformer</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">transformer_size</span><span class="s2">&#34;</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="c1"># number of transformer layers</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">num_transformer_layers</span><span class="s2">&#34;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="c1"># type of positional encoding in transformer</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">pos_encoding</span><span class="s2">&#34;</span><span class="p">:</span> <span class="sa"></span><span class="s2">&#34;</span><span class="s2">timing</span><span class="s2">&#34;</span><span class="p">,</span>  <span class="c1"># string &#39;timing&#39; or &#39;emb&#39;</span>
    <span class="c1"># max sequence length if pos_encoding=&#39;emb&#39;</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">max_seq_length</span><span class="s2">&#34;</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span>
    <span class="c1"># number of attention heads in transformer</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">num_heads</span><span class="s2">&#34;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="c1"># training parameters</span>
    <span class="c1"># initial and final batch sizes:</span>
    <span class="c1"># batch size will be linearly increased for each epoch</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">batch_size</span><span class="s2">&#34;</span><span class="p">:</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">32</span><span class="p">]</span><span class="p">,</span>
    <span class="c1"># how to create batches</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">batch_strategy</span><span class="s2">&#34;</span><span class="p">:</span> <span class="sa"></span><span class="s2">&#34;</span><span class="s2">balanced</span><span class="s2">&#34;</span><span class="p">,</span>  <span class="c1"># string &#39;sequence&#39; or &#39;balanced&#39;</span>
    <span class="c1"># number of epochs</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">epochs</span><span class="s2">&#34;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="c1"># set random seed to any int to get reproducible results</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">random_seed</span><span class="s2">&#34;</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
    <span class="c1"># embedding parameters</span>
    <span class="c1"># dimension size of embedding vectors</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">embed_dim</span><span class="s2">&#34;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
    <span class="c1"># the type of the similarity</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">num_neg</span><span class="s2">&#34;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
    <span class="c1"># flag if minimize only maximum similarity over incorrect labels</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">similarity_type</span><span class="s2">&#34;</span><span class="p">:</span> <span class="sa"></span><span class="s2">&#34;</span><span class="s2">auto</span><span class="s2">&#34;</span><span class="p">,</span>  <span class="c1"># string &#39;auto&#39; or &#39;cosine&#39; or &#39;inner&#39;</span>
    <span class="c1"># the type of the loss function</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">loss_type</span><span class="s2">&#34;</span><span class="p">:</span> <span class="sa"></span><span class="s2">&#34;</span><span class="s2">softmax</span><span class="s2">&#34;</span><span class="p">,</span>  <span class="c1"># string &#39;softmax&#39; or &#39;margin&#39;</span>
    <span class="c1"># how similar the algorithm should try</span>
    <span class="c1"># to make embedding vectors for correct labels</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">mu_pos</span><span class="s2">&#34;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>  <span class="c1"># should be 0.0 &lt; ... &lt; 1.0 for &#39;cosine&#39;</span>
    <span class="c1"># maximum negative similarity for incorrect labels</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">mu_neg</span><span class="s2">&#34;</span><span class="p">:</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">,</span>  <span class="c1"># should be -1.0 &lt; ... &lt; 1.0 for &#39;cosine&#39;</span>
    <span class="c1"># the number of incorrect labels, the algorithm will minimize</span>
    <span class="c1"># their similarity to the user input during training</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">use_max_sim_neg</span><span class="s2">&#34;</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>  <span class="c1"># flag which loss function to use</span>
    <span class="c1"># scale loss inverse proportionally to confidence of correct prediction</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">scale_loss</span><span class="s2">&#34;</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
    <span class="c1"># regularization</span>
    <span class="c1"># the scale of L2 regularization</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">C2</span><span class="s2">&#34;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
    <span class="c1"># the scale of how important is to minimize the maximum similarity</span>
    <span class="c1"># between embeddings of different labels</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">C_emb</span><span class="s2">&#34;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>
    <span class="c1"># dropout rate for dial nn</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">droprate_a</span><span class="s2">&#34;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="c1"># dropout rate for bot nn</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">droprate_b</span><span class="s2">&#34;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="c1"># visualization of accuracy</span>
    <span class="c1"># how often calculate validation accuracy</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">evaluate_every_num_epochs</span><span class="s2">&#34;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>  <span class="c1"># small values may hurt performance</span>
    <span class="c1"># how many examples to use for hold out validation set</span>
    <span class="sa"></span><span class="s2">&#34;</span><span class="s2">evaluate_on_num_examples</span><span class="s2">&#34;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>  <span class="c1"># large values may hurt performance</span>
<span class="p">}</span>
</code></pre></td></tr></table>
</div>
</div><p><strong>注意</strong>：参数<code>mu_neg</code>这是成负值用来模拟原始算法中<code>mu_neg = mu_pos</code>和<code>use_max_sim_neg = False</code>的情况。详细见论文：<a href="https://arxiv.org/abs/1709.03856">starspace paper</a> 。</p>
<h2 id="mapping-policy">Mapping Policy</h2>
<p>MappingPolicy可以直接将意图映射到actions。这个映射是通过给意图添加一个<code>triggers</code>参数实现的，如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">intents:
- ask_is_not:
    triggers: action_is_bot
</code></pre></td></tr></table>
</div>
</div><p>一个意图最多被映射成一个action。一旦接收到对应的意图的消息，助手会运行映射的action。然后，它将会监听下一条消息。结合下一个用户消息，将恢复正常预测行为。</p>
<p>如果你不想要你的意图-action的映射影响对话历史，映射的action必须返回<code>UserUtteranceReverted()</code> 事件。这将从对话历史记录中删除用户的最新消息及其之后发生的任何事件。这意味着您不应该在您的故事中包含意图-动作交互。</p>
<p>举个例子，如果用户在对话过程中，脱离主题，问“Are you a bot?”，你可能想在不影响下一个动作预测的情况下回答。触发的自定义action可以做任何事情，但这里有一个简单的例子，它发送一个bot语句，然后还原交互：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">ActionIsBot</span><span class="p">(</span><span class="n">Action</span><span class="p">)</span><span class="p">:</span>
<span class="sa"></span><span class="s2">&#34;&#34;&#34;</span><span class="s2">Revertible mapped action for utter_is_bot</span><span class="s2">&#34;&#34;&#34;</span>

<span class="k">def</span> <span class="nf">name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="p">:</span>
    <span class="k">return</span> <span class="sa"></span><span class="s2">&#34;</span><span class="s2">action_is_bot</span><span class="s2">&#34;</span>

<span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dispatcher</span><span class="p">,</span> <span class="n">tracker</span><span class="p">,</span> <span class="n">domain</span><span class="p">)</span><span class="p">:</span>
    <span class="n">dispatcher</span><span class="o">.</span><span class="n">utter_template</span><span class="p">(</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">utter_is_bot</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">tracker</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">UserUtteranceReverted</span><span class="p">(</span><span class="p">)</span><span class="p">]</span>
</code></pre></td></tr></table>
</div>
</div><p><strong>注意</strong>：如果你使用MappingPolicy来直接预测机器的语句（如，<code>triggers: utter_{}</code>），这些交互将直接出现在你的故事中，这种情况下没有<code>UserUtteranceReverted()</code>，意图和映射的utterance将会出现在对话历史中。</p>
<p><strong>注意</strong>：MappingPolicy还负责执行默认操作action_back和action_restart以响应/back和/restart。如果您的策略示例中没有包含这些意图，则这些意图将不起作用。</p>
<h2 id="memoization-policy">Memoization Policy</h2>
<p>MemoizationPolicy仅仅记住了训练数据中的对话。如果确切对话出现在训练数据中，它预测下一个action的置信度为1.0，否则为None，置信度为0.0.</p>
<h2 id="fallback-policy">Fallback Policy</h2>
<p>如果下面几点中有一点发生，那么FallbackPolicy将用来触发<a href="https://zhuanlan.zhihu.com/p/89057333">Fallback Actions</a>：</p>
<ol>
<li>意图识别的置信度低于<code>nlu_threshold</code>。</li>
<li>排名最高的意图与排名第二的意图之间的置信度差异小于模糊阈值。</li>
<li>没有一个对话策略的预测结果的置信度高于<code>core_threshold</code>。</li>
</ol>
<p><strong>配置</strong>：</p>
<p>阈值和fallback action可以在配置文件中调整：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">policies:
  - name: &#34;FallbackPolicy&#34;
    nlu_threshold: 0.3
    ambiguity_threshold: 0.1
    core_threshold: 0.3
    fallback_action_name: &#39;action_default_fallback&#39;
</code></pre></td></tr></table>
</div>
</div><p>你也可以在你的python代码中进行配置，如：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">rasa.core.policies.fallback</span> <span class="kn">import</span> <span class="n">FallbackPolicy</span>
<span class="kn">from</span> <span class="nn">rasa.core.policies.keras_policy</span> <span class="kn">import</span> <span class="n">KerasPolicy</span>
<span class="kn">from</span> <span class="nn">rasa.core.agent</span> <span class="kn">import</span> <span class="n">Agent</span>

<span class="n">fallback</span> <span class="o">=</span> <span class="n">FallbackPolicy</span><span class="p">(</span><span class="n">fallback_action_name</span><span class="o">=</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">action_default_fallback</span><span class="s2">&#34;</span><span class="p">,</span>
                          <span class="n">core_threshold</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
                          <span class="n">nlu_threshold</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
                          <span class="n">ambiguity_threshold</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">agent</span> <span class="o">=</span> <span class="n">Agent</span><span class="p">(</span><span class="sa"></span><span class="s2">&#34;</span><span class="s2">domain.yml</span><span class="s2">&#34;</span><span class="p">,</span> <span class="n">policies</span><span class="o">=</span><span class="p">[</span><span class="n">KerasPolicy</span><span class="p">(</span><span class="p">)</span><span class="p">,</span> <span class="n">fallback</span><span class="p">]</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="two-stage-fallback-policy">Two-Stage Fallback Policy</h2>
<p>TwoStageFallbackPolicy通过尝试消除用户输入的歧义，在多个阶段处理低NLU置信度的情况。</p>
<ul>
<li>如果一个NLU预测获取一个低置信度值，或者排名第一个和第二个的差别不大，要求用户意图的分类进行确认。
<ul>
<li>如果他们确认，story正常执行</li>
<li>如果他们拒绝，用户被要求改变说辞。</li>
</ul>
</li>
<li>改变说法
<ul>
<li>如果此时的意图能够正确识别，story继续正常执行</li>
<li>如果改变说法后的意图仍然没有得到一个高的置信度值，用户再次被询问对识别的意图进行确认。</li>
</ul>
</li>
<li>第二次确认
<ul>
<li>如果用户确认意图，story继续正常执行</li>
<li>如果用户拒绝，原始意图会被识别成<code>deny_suggestion_intent_name</code>，将触发最终回退操作（例如，切换到人）。</li>
</ul>
</li>
</ul>
<p><strong>配置</strong>：</p>
<p>为了使用 <code>TwoStageFallbackPolicy</code>，需要在你的配置文件中添加以下内容：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">policies:
  - name: TwoStageFallbackPolicy
    nlu_threshold: 0.3
    ambiguity_threshold: 0.1
    core_threshold: 0.3
    fallback_core_action_name: &#34;action_default_fallback&#34;
    fallback_nlu_action_name: &#34;action_default_fallback&#34;
    deny_suggestion_intent_name: &#34;out_of_scope&#34;
</code></pre></td></tr></table>
</div>
</div><p><strong>注意</strong>：你可以在你的配置文件中引入<code>FallbackPolicy</code>或者<code>TwoStageFallbackPolicy</code>，但是不能一下子引入两个。</p>
<h2 id="form-policy">Form Policy</h2>
<p>FormPolicy是对MemorizationPolicy的扩展，用来处理forms填充的场景。一旦FormAction被调用，FormPolicy会持续预测FormAction，直到所有需要的slots被填满。更多的信息，见<a href="https://zhuanlan.zhihu.com/p/84441651">Forms</a>。</p>
<h2 id="heading">原文链接</h2>
<p><a href="https://rasa.com/docs/rasa/core/policies/">https://rasa.com/docs/rasa/core/policies/</a></p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">grassofsky</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">
        2019-12-21
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/rasa-doc/">rasa-doc</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/chatbots/rasa_messaging_and_voice_channels/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">对话系统rasa - Messaging and Voice Channels （翻译）</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        <a class="next" href="/post/chatbots/rasa_retrieval_actions/">
            <span class="next-text nav-default">对话系统rasa - retrieval actions</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:grass-of-sky@163.com" class="iconfont icon-email" title="email"></a>
      <a href="http://github.com/grassofsky" class="iconfont icon-github" title="github"></a>
      <a href="https://www.zhihu.com/people/zhong-xie-wei-32" class="iconfont icon-zhihu" title="zhihu"></a>
  <a href="http://localhost:1313/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2017 - 
    2019
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">grassofsky</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
<script type="text/javascript" src="/dist/even.26188efa.min.js"></script>








</body>
</html>
